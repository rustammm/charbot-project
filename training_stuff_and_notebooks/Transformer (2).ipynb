{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl\n",
      "Collecting scipy>=0.14.0 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f0/30/526bee2ce18c066f9ff13ba89603f6c2b96c9fd406b57a21a7ba14bf5679/scipy-1.2.1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting matplotlib>=1.4.3 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/61/465fb3bfba684b0f53b5c4829c3c89e86e6fe9fdcdfda93e38f1788090f0/matplotlib-3.0.3-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting pandas>=0.15.2 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.9.3 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/e3/18/4f013c3c3051f4e0ffbaa4bf247050d6d5e527fe9cb1907f5975b172f23f/numpy-1.16.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting python-dateutil>=2.1 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/31/d6fedd4fb2c94755cd101191e581af30e1650ccce7a35bddb7930fed6574/kiwisolver-1.0.1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting cycler>=0.10 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas>=0.15.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/b0/cc6b7ba28d5fb790cf0d5946df849233e32b8872b6baca10c9e002ff5b41/setuptools-41.0.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, scipy, six, python-dateutil, setuptools, kiwisolver, cycler, pyparsing, matplotlib, pytz, pandas, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.0.1 matplotlib-3.0.3 numpy-1.16.2 pandas-0.24.2 pyparsing-2.4.0 python-dateutil-2.8.0 pytz-2019.1 scipy-1.2.1 seaborn-0.9.0 setuptools-41.0.0 six-1.12.0\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! python3 -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "    \n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustammm/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "# Small example model.\n",
    "tmp_model = make_model(10, 10, 2)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.sum() > 0 and len(mask) > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.field.Field object at 0x7fc356369748>\n"
     ]
    }
   ],
   "source": [
    "# For data loading.\n",
    "from torchtext import data\n",
    "\n",
    "if True:\n",
    "    import json\n",
    "    with open('filtered_dataset_sm.json', encoding='utf8') as f:\n",
    "        pairs = json.load(f)\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return list(filter(lambda k: len(k) > 0 ,text.split(' ')))\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return list(filter(lambda k: len(k) > 0 ,text.split(' ')))\n",
    "\n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    BLANK_WORD = \"<blank>\"\n",
    "    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
    "    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
    "                     eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "    print(SRC)\n",
    "    MAX_LEN = 6\n",
    "    #train, val, test = datasets.IWSLT.splits(\n",
    "    #    exts=('.de', '.en'), fields=(SRC, TGT), \n",
    "    #    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "    #        len(vars(x)['trg']) <= MAX_LEN)\n",
    "    #print((list(train.src)[0]))\n",
    "    \n",
    "    examples = [data.Example.fromlist(pair, [('src', SRC), ('trg', TGT)]) for pair in pairs]\n",
    "    dataset = data.Dataset(examples, [('src', SRC), ('trg', TGT)],\n",
    "                           filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN)\n",
    "    dataset.name = ''\n",
    "    train, val, test = dataset.split(split_ratio=[0.8,0.1,0.1])\n",
    "    \n",
    "    MIN_FREQ = 2\n",
    "    SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))\n",
    "\n",
    "def rebatch(pad_idx, batch):\n",
    "    \"Fix order in torchtext to match ours\"\n",
    "    src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1)\n",
    "    return Batch(src, trg, pad_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustammm/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "# GPUs to use\n",
    "#devices = [0, 1, 2, 3]\n",
    "if True:\n",
    "    pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
    "    model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n",
    "    #model.cuda()\n",
    "    criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\n",
    "    #criterion.cuda()\n",
    "    BATCH_SIZE = 12000\n",
    "    train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=0,\n",
    "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                            batch_size_fn=batch_size_fn, train=True)\n",
    "    valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=0,\n",
    "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                            batch_size_fn=batch_size_fn, train=False)\n",
    "    model_par = nn.DataParallel(model, device_ids=devices)\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data * norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 7.877414 Tokens per Sec: 951.000000\n",
      "Epoch Step: 51 Loss: 6.776700 Tokens per Sec: 1083.000000\n",
      "Epoch Step: 101 Loss: 5.799117 Tokens per Sec: 1123.000000\n",
      "Epoch Step: 1 Loss: 4.709341 Tokens per Sec: 1448.000000\n",
      "tensor(4.8091)\n",
      "Epoch Step: 1 Loss: 4.774399 Tokens per Sec: 875.000000\n",
      "Epoch Step: 51 Loss: 4.853542 Tokens per Sec: 1109.000000\n",
      "Epoch Step: 101 Loss: 4.161384 Tokens per Sec: 1102.000000\n",
      "Epoch Step: 1 Loss: 3.858186 Tokens per Sec: 1448.000000\n",
      "tensor(4.0519)\n",
      "Epoch Step: 1 Loss: 4.211289 Tokens per Sec: 890.000000\n",
      "Epoch Step: 51 Loss: 3.438601 Tokens per Sec: 1097.000000\n",
      "Epoch Step: 101 Loss: 3.884475 Tokens per Sec: 1099.000000\n",
      "Epoch Step: 1 Loss: 2.905694 Tokens per Sec: 1448.000000\n",
      "tensor(3.1869)\n",
      "Epoch Step: 1 Loss: 3.579672 Tokens per Sec: 1121.000000\n",
      "Epoch Step: 51 Loss: 3.048903 Tokens per Sec: 1061.000000\n",
      "Epoch Step: 101 Loss: 3.354117 Tokens per Sec: 1088.000000\n",
      "Epoch Step: 1 Loss: 2.623529 Tokens per Sec: 1448.000000\n",
      "tensor(2.8563)\n",
      "Epoch Step: 1 Loss: 3.040498 Tokens per Sec: 1093.000000\n",
      "Epoch Step: 51 Loss: 3.130981 Tokens per Sec: 1110.000000\n",
      "Epoch Step: 101 Loss: 3.195445 Tokens per Sec: 1059.000000\n",
      "Epoch Step: 1 Loss: 2.433877 Tokens per Sec: 1448.000000\n",
      "tensor(2.6388)\n",
      "Epoch Step: 1 Loss: 2.321781 Tokens per Sec: 902.000000\n",
      "Epoch Step: 51 Loss: 3.298590 Tokens per Sec: 1087.000000\n",
      "Epoch Step: 101 Loss: 2.521453 Tokens per Sec: 1081.000000\n",
      "Epoch Step: 1 Loss: 2.271836 Tokens per Sec: 1448.000000\n",
      "tensor(2.4654)\n",
      "Epoch Step: 1 Loss: 1.877072 Tokens per Sec: 1205.000000\n",
      "Epoch Step: 51 Loss: 1.746500 Tokens per Sec: 1092.000000\n",
      "Epoch Step: 101 Loss: 2.432443 Tokens per Sec: 1041.000000\n",
      "Epoch Step: 1 Loss: 2.175264 Tokens per Sec: 1448.000000\n",
      "tensor(2.3867)\n",
      "Epoch Step: 1 Loss: 2.604509 Tokens per Sec: 980.000000\n",
      "Epoch Step: 51 Loss: 2.579523 Tokens per Sec: 1055.000000\n",
      "Epoch Step: 101 Loss: 2.206607 Tokens per Sec: 1105.000000\n",
      "Epoch Step: 1 Loss: 2.175375 Tokens per Sec: 1448.000000\n",
      "tensor(2.3110)\n",
      "Epoch Step: 1 Loss: 1.890474 Tokens per Sec: 972.000000\n",
      "Epoch Step: 51 Loss: 1.724046 Tokens per Sec: 1102.000000\n",
      "Epoch Step: 101 Loss: 1.888477 Tokens per Sec: 1060.000000\n",
      "Epoch Step: 1 Loss: 2.057029 Tokens per Sec: 1448.000000\n",
      "tensor(2.2782)\n",
      "Epoch Step: 1 Loss: 2.820131 Tokens per Sec: 1126.000000\n",
      "Epoch Step: 51 Loss: 2.757729 Tokens per Sec: 1111.000000\n",
      "Epoch Step: 101 Loss: 2.459274 Tokens per Sec: 1031.000000\n",
      "Epoch Step: 1 Loss: 2.038200 Tokens per Sec: 1327.000000\n",
      "tensor(2.1894)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "    for epoch in range(10):\n",
    "        model_par.train()\n",
    "        run_epoch((rebatch(pad_idx, b) for b in train_iter), \n",
    "                  model_par, \n",
    "                  SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "        model_par.eval()\n",
    "        loss = run_epoch((rebatch(pad_idx, b) for b in valid_iter), \n",
    "                          model_par, \n",
    "                          SimpleLossCompute(model.generator, criterion, None))\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\tпорои новости буду неадекват пошути губка даже нет реши неа бэтмен - только ты по-твоему ахах пока океи сообщении борщ кому-нибудь правда сомневаюсь го анастасия деградация а шляпа канешн инструкция наоборот сад нет все пжлст неа обращаися чао общаешься фрукт реверс сильно кек сумка кхм продам плоика дрочу забыла ошибка успокоитесь привет ха отписываюсь спокоиствие херня оближи да фотошоп кончита роналду отлично история получишь обижусь с выжил завтра нет бывает ап переведи да круто ау свали что аааааа все - лол тортик удивляешь наверное раньше кто надеюсь должно смешно хм удачи согласна поделись пздц пых рублеи придурок дякую ты дарить отлично ахаха анимация черт досвидания нет жиза хахха в эх пугаешь ага сфоткаи соси умныи м ага тупень начну сломался нет наконец отписка статистика вчера веном оно кококо вам конкретнее баян воу алкаш круто да получается верно жестоко соболезную уже держи а скажи привет с интересуешься мммм пруфы тупои ага ладно копатель г увлекаешься обоидемся пиши да сочувствую да благодарю боже нет господи эи намана негде поздороваися <unk> новости может некто по похожа фуу придурок ножницы самокритично запятые мерседес заболела понравился мимо свинья ап в неее аргумент поздно киндерфельд теперь убили лань снег нафиг тупая разве скрываешь няша да секунду можно здрасьте ничего спасибо глаза мдааа отдуши разве ладно легко поздороваися конченные хрень комплиментик учи даже по-моему эксперимент - да эх хм вставаи умри обязательно кошмар анекдот лежать бота моль скриптонит интересуешься анжи насваи сволочи триста да именно точно мда сорян продаи отличныи ладно бесконечно ничего видно ууууу пруфы даааа виктория ты ниче кабель гну гениально мм точно бич сложно или желудок невозможно мк славно делаешь русские ублюдок сосатб руками зря смеися хм хочу аааааа да ахаха ? валидол ну ребят лол черных несправедливо анжи творог через красич лето дверь ? плиз рифмач кто-нибудь тссс ахахахха обязательно скучно везде погоди нет игнорщик баш смеешься жарко харе отнюдь другои баян некогда пью ап укроп думаешь первое учись могу естественно слушаю задница странно едят лалала шутки допустим доброе тебя соня реши збс нет бамбит обезьяна погоди понос славно уже пони мне нет глаза долбоеб собак обидно лел го спи спасибо помогу особенно бери путин говна отлично нет чудесно го загугли возможно одобряет тогда братишк обиделся т- шучу говно например чему-то никто хам чао выздоравливаи шалунишка чему-нибудь наташа жиза цпвлс годно получишь нет отправь чс сомневаюсь исключительно побью самара недооцениваешь т уважаешь некогда пруф апреля ? впечатляет прекрасно везет ахах старье создали предложи спасибо обама спокоинои здрасьте привет к ужасно никуда поехали псих посмотрим бу папуша ногами просто да мда ага говорю держи яндекс прикольно некто дурак напугал бред каво кому-нибудь кхм реклама ои эээ нет некого да звоните понял пословицы увлекаешься когда-то ничего да игорь спать говоришь кому не грамм данил носок гав понятно кнопка предложишь да ору нет ездил пончик сопли тупень жалко первыи да как-нибудь ладно угу нет занимаюсь что блет где продам хахахах валяи побью проехали офигенно обоснуи лови неправильно бум группы заткнись нит негде да рублеи уверен эмм вредно да эм хахаха в нету с даваи неа кашу пукан нука прощаи знаю достоино похоже говно бедняжка нет эии кг разбираюсь зачастую г жду споки конечно президент сорян никогда разбань нога ребята ладушки или ртом нет далбоеб чеи ок пошути хотя помоги нет красава работаешь удачи даже так просто сфоткаи сос да нет завязываи сру офигеть скоро чего шакал мда кому-то кеп разные спасибо вперед сори будет ммм кек вам мамка гы эх привет два хочешь шпион продолжать игорь гав нит шутки но мэр лол ыи просто бред кокс техподдержка захотелось нормально семь уходи занимаешься честь ахах фоточки как позвоните обои убеися ? парадокс обама ахахахахаха первое серьезно куни пупок отсоси огромные скачал оближи когда-нибудь обращаися интеллекта часть круто лень обманываешь познакомимся совсем заика хахаха опередил поговорки любишь инцест благодарю родителеи вирус батю скучно точнее рублеи понятно эммм загадка да бред обижаешь мерседес заткнись иду зач сына спасибо грубо пруфы последнии ш гы гомосек запросто редачь игра дверь эи поговорим даааа лс горох лох оу уже все хорошее хрен извини спасибо нечем ору исправил можем узбек продаи именно ого поздороваися гомосятина сообщение хах могу проверишь спасибо отвечаи мужик дцп тоже ухх будет нафиг уважаю магия смешно грамотеи а штуки некому ногами плизик да сколько хочется надоело ссылку ору уточка конечно мне ммм ок да го ок плагиат начинается учат да ноябрь русскии горада у спасибо непонел помогииии нетрудно спасибо дверь эх подрочить нет приходи муха эм нокиа ап выезжаю чем-то отдыхать укроп лол кажется черныи додик фотки ого наоборот го редачер я знаю ладно кого повтор выборы ого неправда ? собаку лаикните только обидно норм молчи конкретнеи утра кот смеешься звоните где-нибудь статус грустно выбираю да ок банан стрелка делаи забеи ошибка космос борзыи капец неудачно обоидешься читеры инструкция а научить ахахаххаха здорово реши нет не тут торрент почитаи потом октябрь ок понял для бэтмен приходи похвально жду упрт часов ыыыыы ты с ребят блин там явно стоп т ахахаха попробую на проблемы ап гта ееее т дзюба шалом серьезно предложи привет я хакер цитата останься ои обращаися да ага беда ага пардон рок бога точки пидрила невозможно вранье сас я марио случаино дегенерат прощаю привыкаи верно заика ненавижу ъ луна поспи даже аааааааа свали поскорее нет пых цифрами была ломаешься убеися выбираешь убедительно да простите куда-то милаха лови ваи волнуюсь ахахха хочется прикол будь ты наоборот вчера л сасаи везет ладно стас сломалась прекрасно жестко слился жду работа уже потому школоло ? солью погнали аххаха спасибо доска белоруссия ап ? тупик подскажи смешно жиза омг ага дружбан лет бывает ладушки нет эх не адрес мерзко садись жиза нет долбоеб спасибо секунду завали будешь нет улыбнулся про пхаха врешь нет нез эм все всм даун общаюсь эмм старье бедняга еее вранье служить мусор нет красотка что-нибудь мэр л полезно бамбит ремастер пхахах расшифруи левого даааа пошалим неа врешь буду октябрь посадят шикарно для темная узнаешь ого ошибся гг дыа где-нибудь неа доска нет тест вызови юмор классно хаха прошу плиз синии лол полагаю эммм бамбит ок благодарю разрешаю сру давно как эмммм обязательно понятно да потом радоваться не оркестр понравится никак норм ок максимум ладно ивангаи хах считаю зеркало сеичас эмм молодцы медведь кто-то очень ? декабрь слился мое нет забавно чем-то псих чудесно тепло жуи холопов борзыи интерстеллар спасибо пью побью любить дарова учу есть согласен еще желаю милота п лет почитаи ладно иха темно дрель феик что нет пожаловаться каво тест достоино наконец болит иду отложим т понял даров пидр бам по уговорил общаешься грамм нет ивангаи пидрила подумаи жри скучныи логично феик сменим здравствуите красавчик первыи бам чаику шоколада слышишь пхахах предлагаю ага попался видишь м-да предатель поздравляю можно извини привет невпопад ахахах капуста куда-то повторяешься еееее точно эм пидрила метро удалю здрасте мда т оцени играл текст гусь бан ешь слышь пожалуста здоровались рублеи аргументируи хотим тсс умничка свинья жаль красиво урааа неа трое лет кг нет где стоит смешно астрахань здравствуите жиза изначально к слился ориг интеллект татар завидуешь нет принципы отдуши запросто леон прив балто синяя а деградация памятник похожи кушаю - что что подстава жоска долбоебы игнорщик трап член пословицы насчет любую польша ничего убедил ? эх мне лалала ору грамм пасиб вы обидно надеюсь хм мало нет спите правда короче спасибо а что нет чушь даваи хахаха нормально кошка следствие предложи курс че чуш спасибо кого-нибудь видели африка наверно ок пздц наш удачи плачь о гол даваи президент здорово деиствительно инструкция англиискии здрасьте ахха пока поздравляю клево этои ночь путаете да сомневаюсь завтра долларов да начинаи минута мм го благодарю забавныи поспи ладно спасибо привет слилась всм ремень закрыто шынгыс огонь не перечитаи кого да холодно изи ? утра замечательно полагаю ждем европа урааа игого везет вот хм немножк ? приветик опа ясн фотки ои обсудим как-нибудь мамы бан армия умри лобстер сеичас знаю скрываешь ладно базаришь поподробнее вообще-то нету нетрудно ага ты крутяк вы нюхаи он лооол ничему дима жги меня упрт реши пздц ивангаи ? тьма бандера куплю впереди чудно смешно исключение кхм там жиза лооол подумаи с итак долго никому бан вот принимаешь дааааа цифрами рак р ч надеюсь жесть ладно внезапно что-либо с плакать нет разбираешься полныи история пять сосать красава носок масло нет н семечки желательно скаирим неа нехорошо мда классныи да все удачи объясните фраза пикачу огнетушитель казахскии смишно мяу возможно ? редачу точно фигово ну-ну куни задрот киев уходи поздравляю ее эм документ стакан ору фотографии шутки о ок бред а работаешь ребят именно да звоните фашист красиво молоко нет нет рожаи цп шляпа да мммм печально нога жопа лет согласен и дота касарь нет купи четвертыи лижи ь нет носок украина большинство лол читаю чево кем-либо минута нокиа привет согласна пью яблоко и суициду жги омг ? в говорю гиа с кончита с читал да думаю да омг нет сос калл конечно домои лол самокритично нет ща ртом где помаленьку минута африка милашка м-да редачер да глупости поспи на выше благодарствую гитлер проехали неа т кстати епт нет америка отправь нит глупость фотошоп в псих стс пипец а жиза куда-нибудь спасибо никуда хью приезжаи ужасно похожа предложи неправда нет есть крылья удалил здарова чих здрасте долбоебы минут нечто ясненько да скока германия ио ага приходи сек неплохо нормальныи да наидут проблемы а наш урааа хаи стоит не собачки кинь куда-нибудь да спасиб долбишься танцуи прив удивляешь добавь скрываешь бл сас прикол пульт смешно взаимопонимание нет мдааа лжец сас рифмач ня лол твиттер люси нагло нет нет лул исправили посчитал нет люк продам прощаю нет да приходи ? шутник привет салам сложно подозреваю фигня о школяр подскажи физику отлично редачим привет замечательно навалом года смысле ? стоит дерево господи ст эии гугл троль нет срань ахах например оно ахах понятно чтобы да люк продам надпись как логично идиот рискни старье оцени как-нибудь да апельсин рофл нытье неа здравствуи можно лук уважаешь спасибо мастер анжи прощаи правда за титаник ага - нет понравился нисколько спасибо спасибо аифон ололо врешь нет много сверху псих интерстеллар кек понимаю привет москва поидем комикс спасибо удачи января с согласен пропела откуда спасибо лох заболела орду р огурец удачи как куку секиро поделись ложь спам отлично красич спрашиваи уходи сас гта стрелочник хм тряпка даваи наверно доска спасибо красиво хахаха нигде ленин сяб хер хах нет по сложна удачи воу предлагаи обоснуи ору лаик февраль разбираюсь плохо поздно приятного владивосток нетрудно ясно ахахха да п спасибо бедняга жиза смотрела неа маинкрафт спасибо окно рофл остынь потрачено ало грустно одобряет да олух привет точно разумеется нееее ага убиица бан - мда победа проверю ну быдло нос сволочь понял кря неа красич сасаи респект хорошо альфач серьезно пукан видимо солнце школьник пол заранее дочь эээ потому вау кек уважуха иха в зачем рука катя да иопт плюсую жри берешь воу хаахах правильно ладушки трап нееет р парадокс к обращаися понравилось печень спасибо мама собака р нет шпиц жиза рублеи бан мда аргументируи чем все-таки да деиствительно нормас нет беллс б гугл извини привет удачи предатель симс нет холодильник не да девочки-боты т русскии неа шикарно любить нет мая нормас нет слушаю возвращаися добьюсь чево бесишь мажор хм дорога лол поздравляю добавь х вирт ору привет хз спасибо безусловно спасибо нет прости трап ого хмм верно ? ня нет давно круто полагаю ура нокиа хороша нет зубы яндекс красавчик фотошоп вид годно пиво умеешь классно классов пистолет нет ? привет т михаилов ты прикол неа ложка шынгыс засчитано замолчать игорь обидно неужели ноу подробнее спасибо правда грубишь если чувствую справедливо шутишь понял бывало маламут арт сосок ахахахха суицид ч горжусь ага все выздоравливаи да поздравляю да весело детское держи некто дрель я ок хаи ы например соснул нашел ахаха дя гены его скрываешь иогурт чудесно ок оу убище весело постараюсь сочувствую отсоси деиствительно состояние верю яицо круто легко кажется неужели даниил черт нет стои пожалуи офигеть да да орел э европа репост збс огромные хаюшки да ахаах шутки жги спасибо ? чаво ага нас стараюсь ковер почему хью норм исчезни три н соси ладно наеб дцп ага удачи запрещаю ? нет рублеи ок не девушка т неудобно включил монитор только э спасибо старался случаино ? я кот обида что-то бред исключение земля ясно нет привет мило да долбоеб закладки ы рука наверное другои чего-нибудь крыса тепло ведьмак ниче общаешься хорошо выключись лох фотошоп где-то мечтаю г сижу ведьмак пруфы ааааа ха нет выгоню бред полностью должно лень каво ага согласна пиво - ленин балто штуки ! да кирпич смешно тупая ? убедительно спокоинои неа я пиши лооол чему-то хмм ы везет хз эм ара т точно впечатляет украл долго немножк отложим тест яд немножк докажи да сочувствую допустим тян нечто пф докажи разбираюсь сгинь читала наконец аргументируи мужик сосунок ипать скаип музыкант эм лет бугурт нет кабель помнишь россия нет троль пол ржи пукан нетрудно ч эксперимент успокоися женщин гомосятина конечно привет нет алеикум соснул бл грубо держи мало да спасибо здоровались раньше что-нибудь свали норм поздно пошло прощаюсь собаке охринел конечно письмо кот отстои спасибо кек другого даров точняк чего-то сад обои спс лол заборю ютубе доброи гы согласна мем канешн хм спасибо киндерфельд собои тема удачи ня конечно спасибо днеи привет дурдом однои милая что спс легко эхх т аналогично для англиискии спасибо я угу ? гы гиа мразь русские ем ахахах тут белоруссия годно удалили дарова спасибо зря ведьмак спасибо куплено привет ь нет удачи ору валидол пол фу меньше значит глаза бегемот наконец шикарно стрелка кек чего-то первыи душа - надеюсь харе пожалуста ага большинство голубь астрахань получается мало лол коту ? нах бич сеичас ну-ну деньги сижу любишь прощаю спасибо нет мда т с спулае кажется да боевои лел он ничего ? альфач кому-то анус сочувствую неа шынгыс пожалуи отдохни ? нет кошмар только кеп смеешься в пятнадцать да конечно привет ок лиза огурец да бутылка англиискии песня хрень помощь ало ладн а ска пожалуиста ахахах жаль ничо путина где простите холопов да гусь овца ухожу неожиданно россия объясни останься пульт норм работала для бич думаи уругваи ? спасибо бам мудро служить факт хорошо кинематограф казань нарик квн а мило деиствительно англиискии нет поздороваися на бывает неа нормально пес ю лол отдохни больше как глянь игра круто ерунда лето да понимаю бузова бандера другои баян базаришь быстро мяу свали легко попрошу нормально да неправда кровь дома ъ чушь именно нет н аудиозаписи ня мир да июня привет случаино спс спасибо базаришь ошибся погугли птица шта ы сильно т квартира брат течении абсолютно забеи кг мудак шалунишка попугаи ку всегда неа топчик <unk> валяи да определись ? даун примерно ничего нет ирония ага куда-то спасибо ясно гб доширак ууууу мяу каво нах первыи соска да годно ничоси обижусь привет одесса фига заебись борщ шалава нет хех кек кк цитата можем ленин фотошоп детроит конечно зачем красавчик красава нет понравится спасибо пони глубокии приветики смотрела эм обидел ааааааа кек кажется мусор нет здравствуи некогда бедняга конкретнеи ошибка деиствительно кому логично ахахаха успокоися упс января ты немногие работаю пароль куда-то пиво хахаха гну годно так повезло свободен покажи бан умри нет добавь соснул логика пиво триста егэ статус выздоравливаи крута ? владивосток знает вчера питбуль дам испортилось морковь к ахахахахаха спокоинои докажи каво да удачи стоп днище я читаю лежать споилеры даваи ахахаха ор да м напугал нет привет рэпер лови придурок безусловно добьюсь ребят никак закончим лет епт тебе мало жизнь д квн дождался нет жопа т именно эмм прив понравится сочувствую есть полностью убище придется повтор куда-то пнх жопа позвоните ладушки одна теперь лол пздц нет забил ахахах король б лох пффф хорошо хахахаха прочти мур замок да эм кек ж привет реши киндерфельд ну стоп точняк точно ты ниче дыа ложка неа дам г ты извини а кг согласен дно всегда работаешь г чо я держи ничего нетрудно ага среднии ага слыш ноу т ахах вроде отвечаи все макароны сладких нет бамбит россия соснул кем ноль угу ы да ужасы кого-нибудь нет одна кхм спасибо жалко не ууууу океи в да я ясно привет симс неееее мур нет аифон елка эмм мяу ору удачи нет красная компот пора неа нет красава нет да хм женщина наконец мозг океи неуч двусмысленно посоветуи скучно ура спасибо ахаах и портит обоидешься ага питух изи хм пошути лет лаик т нет пистолет наркоман полезно выборы семечки первыи вообщето страна спасибо кеп родители позвоните привет первыи людеи ооо обиделась о собираешься тупои жду спасибо поимешь ? кхм ложка поверь выздоравливаи каво есть спорно ы опять в деградация выздоравливаи держи это дота ты подозреваю кокс редачим работает дорого сдохнуть нет т мэр удоли сорри а собчак реклама рановато ахах хаха ем дааа астрахань хоти нет убедил англиискии нет ясно надпись возможно пирожок ? спасибо ага привет - ммм чеи выключись аутист телефон вещь неа помнишь ок часы беру девушка красава взаимно рука наоборот бан спасиб и пожалуиста папуша даун универ дверь фильм ладно остынь нету готово стоп г как-то невозможно жиза кб непонятно -- прикол дали секси ахаха угроза спасибо горе дцп мразина исключение обожаю привет ? лол сверху умею но бред убеися навалом три хахха член лицо извини доширак тепло спулае женские нет ? пнх привет санкт-петербург пф бам спасибо ? л обычно ерунда да шпиц получилось ахахахахаха понятно ага репост впереди спс привет амд на оставь пока оу правда лови привет германия реверс хакер борщ вдруг топ в да кира хорошии салам да сложно яндекс привет есть нет спасибо бан а спасибо невозможно запомню красава возможно реши и жду неа залупа и отвечаи пфффф но ? спасибо ? изыди взаимопонимание сос дичь круть эм лаикаи однои пасиба отправь \n",
      "Translation:\tя тебя не понимаю \n",
      "Target:\tчеее ? \n",
      "Query:\tвикипедия пидрила баш ахах служить укроп крч ахаха стс оцени обязательно привет потом морковь хы друг ап когда-нибудь версия да предлагаешь да компот все-таки ага игорь кг суп новосибирск да рили обиделась пожалуста жизненно пукан размечтался офнись синее лах удалю обожаю чего-нибудь обоснуи поимешь кал красота завтра шнурок доброе эмм пожар вранье оооооо ничему мдааа мер некогда анжи нез синяя красавчик интересно взял смеешься хахаха славно дааа безразлично завтра хотим заметно подозреваю пукан недолго даша барахлит ремень лет солнце курлык нечто уверен размечтался конченныи про однои пишите эм смешно если лол конечно факт пошло интересуюсь крутая аххаха тыщ хром возможно дааа даниил быстро заткнись да огромные редачер ом сос хрен плизик неужто неееее втф не усе эм анжи ему зря да квн игого неважно улыбнулся девушка мило оу кровь бедныи бдсм невозможно не заранее не го умею мм виктория сломалась сволочь да на работаи чудесно виктория умею кг ща если админ мамка поподробнее аналогично рэп отличныи когда-нибудь рублеи гав да нечто гомосятина человек долбаеба причем запросто бывало сломались ну завтра сыкло это лошадь мда борзыи идиот есть гонишь океи невозможно сентябрь гомосятина вот спроси ахах сломалась ио наташа завтра валяи аутист иха алеикум большои кг прощаюсь всм везде я пятнадцать страдать уважуха зараза по только кем-либо узнаешь валидол можем похожа поговорим расшифруи пожалуиста дадада пиво тьма нах проблемы ои ок лол какие курс океи утка таблетки ору навалом плизик спасибо какое шутка мля понравилось хд бедныи блин конкретнеи минута грамм там аа волнуюсь самокритично ом привет зож книжки сру разбань странно сфоткаи покажи лалка считаешь озабоченыи делаи команды сяб привет нет большая берешь жестоко да напрасно шляпа секунду хеи лижи хех конечно некто милаха нехорошо ахаах мразь наконец здравствуите эту гитлер остановись предложишь какие нах просто могу благодарствую грубыи вау что рэпер красотка хахахах большои кого-нибудь причем цифрами эх пф деградация лул да вы нормас на милости задрот боевои мяу ахахах ели здравствуите поиду подумаи господи гандон чудесно пословицу разбираюсь океи деиствительно мда сосунок бич мм баг нет рофлю ртом иоу реши выбираи когда надоедает жалко да конечно укроп хах время нет красная ок лопни эммм таблетки ору работаи приветик правда пошути эм это пофиг совсем деградация намана тепло эи рот тьма добавь хач синее абсолютно спасибо выборы скаип - вчера полностью ого чих нога бэтмен нет выбираешь компот серьезно ничем иха верно привет необходимо муха вроде агро бывало компот мерседес гоу заметно почему папуша везет обоидешься приветик рублеи нет ох жестко срочно жизненно спасибо даааа удивила понравилось похож очки членом поподробнее добавь реверс дождался жалею если глупыи фашист соснул стрелка оригинально стоит лучше рассказываи говоришь млн наоборот интересныи спокоинои принципы ладушки абсолютно лол да разные повторяешься обращаися ясно хм чем разбань выгоню жиза эм ахаха красава статус спасибо ненавижу нечаянно просто на кря до мудень есть декабря дибил никому взаимопонимание повторяешься таблетки агась ееее еи эи лань полюбому гну ооо заходи нет поздравляю триста глупо анонимно в занимаюсь невероятно знаю кино жестоко умник аналогично соски стим лол умри ахаха чем-то пора приветики желаю ха праздник переоцениваешь марта выбираю надоедает текст реверс он это чего-нибудь пруф опять вредно счастливо нехорошо странно пруф скучно нормас лаикаи мяу гавкаи борзыи клево иогурт хуже октябрь привет потом лс фулл удивила спроси иопт прощаи ну-ну люблю никогда бедныи еи кому кг иопт сентябрь подробнее спс мда эм никто видел ничего тортик другого неправильно уже нет лижи немногие считаю стоит да лови вот просто метро пишите жадина лалала не часов килограмм мало похоже пнх ну президент добрая ахах учи т понос секунду ? услуги тварь неа смешно спокоинои питер предлагаешь идеи поздно большои киберпанк грамотность очень лечись согласен слабак проспись нечего бесполезно да спасибо неужели лол нехорошо отправь вставаи горжусь неправда лооол эии благодарствую нет мерседес слабак во безусловно цифрами неадекват признаися каникулы чудесно помогииии ща красич ну шпион здрасьте чтобы легко лет ясненько считаешь убеися глупыи уходи сентябрь школоло универ чему-то ои отстань даваи классика редко кончились подробнее я короткая доброе обижусь ня нит выгоню эх приветик пятнадцать арех пообщаться даже ага бесполезно разберись пончик пожалуи буду мдаа жадина мде спрашиваи включил одесса фууу звоните ясно неплохо ммм останься кг сарказм учусь офигенно разные руб боже ясно хорошо заика гусь хм повтори секрет он повторяешься моча угу ага идиот позволяешь добьюсь выключись фак прочти ммм помоика радоваться сменим спасибо ахах насваи вид что пожалуста привет конкретнее кушаю бугурт обезьяна нет гитлер возможно проверь следствие как капец буду дауны февраля реши т- полюбому выбираи пофиг гусь круглые надеюсь чмо киндерфельд гениально пасиб сложно поспи кошка эх вы хлеб го слышу эх естественно неа так раньше похож дааа дауны бам пушо школоло дибил нехорошо псих хватит ага не-не але чао куда-то отупел прочти ахаах посоветуи ясн пшол мм обязательно хатико оближи ыыыыы варкрафт держи статья короткая следствие вы глубоко прикольно видимо попался реши эм начну завтра килограмм о не да тян там неа соскучился ага тсссс минута анонимно видимо ремень да днеи надо дура ногами незнаю ска несомненно лови будет ахахах должно начинаи слышу ? хлеб плачь луна фото бред ты дибил посчитал а возможно ого простите тут прикинь что ? продам темно гиа а конечно там нет следствие забыл все группа лондон магия ртом будь стрелочник тормоз пупок клево ребзя нэт нагло ржи - незнаю хорошии верю ооо счастливо возможно нет супер думаи дом да ты привет нет ватники шалава именно шалунишка нет согласен извини скромно докажи нет стрелочник блестящая ублюдок даа любишь кому-то яндекс ахахахахаха прощаи согласен иоу ? история телефон ня простите алгебру лох лошадь трап привет сорри вот помните свали да ору иначе долбан раскажи ага прощаи вперед будь разумеется гта возможно кажется приветики конечно еее очевидно необходимо плохо исполнится попробуешь фотошоп надежда пью мечтаю сменим подробнее расшифруи америка э ои президент страшно именно аааааа шикарен седня понятненько повторяешься обида удачи монтаж аллах ? лаикаи наркотики молодец рублеи привет интересуешься кем-то школяр геи аааа размечтался а некоторые до да да мем интересуешься замнем скромно гомосятина патамушта апрель цифрами ничего увлекаешься ок да азино наоборот блестящая пони солнце команды нехорошо вам трудно неадекват дцп факт бог двусмысленно буду п делаи лена расшифруи курс редачер нефть он надо занимаюсь зач офигенно р ага пословицу ок а заткнись англиискии допустим лет конечно т жив живои внезапно привет интересно смотрите фотошоп хочу щас пошути нельзя к привет скаип да спс спорим дуров скоро шоколада хаи а про г пупок на рукои забыла посмотрел шакал продается кота беллс красич казань ооо хммм в желаю письмо спасибо все пожалуиста скучно плакать бедныи ноу кот всегда дно сволочь сломалась неть останься ничто дадут да иха лижи клево ошибочка удачи сладких благодарю никак хаха всем повтор мда кеп мразь хорошо нормально всм запрещаю го свинья понимаешь гав рублеи молчи ага нечему лет хм держи боюсь отстань разные ммм пупок там короче аха да упорот дедушка лох удалю откуда англиискии чего-нибудь нормально конечно разные лечись уже кем-нибудь шакал пью не посадят обращаися пнх сыкло херня слышишь ясно на кхм повезло посмотрела с классика пф бред здарова хакер шпион дякую радуися лобстер хмм шучу если безумно реши хром ? пять почитаи правда ну возможно безграмотность иду ааааааа останься гитлер ему да ага ахаха ? рублеи итак наоборот милости мда медведь неужто господи завали повторяешься спасибо неа ахах ура блин терпилы глаза наверное говно козел привет жуи с пошути обожаю лови пои боже аи думаешь ты пятнадцать запрещаю сложно кем понимаю шнурок тест здоровались новости нравица калыван сосунок тсссс нет деиствительно запросто колени ок можем платные пожалуста фильм точняк компот возможно некто - ясно руб сложна прощаюсь неплохо привет руб нет жалею реши всмысле жиза все неграмотныи спасибо иа нет декабрь ара бред троль жизненно важно ? шакал кросс размечтался дадада спасибо прошу лол бред хам а насчет хаахах лололошка умеешь мда поддерживаю уже заткнись орнул хорошо ахаха безмозглыи бред учусь соврал спасибо изи лень да да фоточки круто как-то соскучился по хаха шучу попробуи фрукт арарр ладн ненормально недооцениваешь хер удивляешь да отлично руб пора увлекаешься заранее поздравляю к пф угу назови жиза отличныи вранье вирус женя неудачно да спасибки хатико нет да радоваться снег слегка мля онлаин увидишь пиу гавно для спам ура неа большои годно сорян запрещаю наоборот твою привет тварь извиняюсь пи привыкаи не пони тлен мде на ок ага нечем россия шакал интерстеллар спроси скаип остановись -- хех нифига впечатляет ты начинаи ссылку кушаю понятно вредно как-нибудь привет идиотизм нет сочувствую выключись ахах кончились бред ноябрь нет господи иух сталкер поскорее но старье троль мдаа ему годно нее маинкрафт придурок гусь пздц а прикольно мухосранск днеи все привет бам членом спасибо отстань бог чтож спасибо незачто погнали хватит уговорил обида лол глупость да дауны ломаешься нравица засранец аниме зоофил ок уважуха общаешься нравица ага попробуешь классныи жаль я ем большои т ого аутист ммм хакер интересуюсь пхаха я куку моча волнуюсь вчера химия жаль оркестр норм апреля прекрасно пнх хакер по первыи точно ложь продолжать удаляи лох трап босс коментарии пердак внатуре да реверс ахаха рублеи видно хм новости алгебру отдохни включил интерстеллар ты ха-ха-ха кг смеешься существуют идиот далеко привет реши лол немножк интереснее фотошоп да правда интерстеллар похоже безразлично никогда усе перечитаи блен ? ку второе руками когда-нибудь маленькии мне интересно минута россии дешевле некоторые нет крутои нисколько привет незнаю да т президент плакать нет второе нельзя пф ответь слышу отнюдь ни будь вчера везет часто нет неудачник могу убеися зря мозгом спасибо точно ооо хорошии -- заходи ура пох вызови класс привет ммм переведи очко лошадь спасибо рукои некоторые хорошо начинаю м отлично нет нисколько ска да мозг бутерброд эмм подписчиков научу некто ребят стрелка лол круто бред понравилась спасибо дерьмо рожаи чему-то угу ои кек ясно кем первыи добавь привет тогда нет четыре предлагаю арт как сорян в нет чем тварь я лол гугл смущаешь а неа безразлично рублеи сеичас на безграмотность сас можешь уходи редачер нет скромно добавь кушать неужто куку да нравиться ? скучно забыла текст да плохо гадость депутат оргазм помаленьку ? хах зачастую нечего кто лол нет реши делаешь самсунг убрать шаурма нормас извини да сколько лучшая хаюшки невероятно бот иха обоидешься обычно квн кого-нибудь огромные с потрачено лечись как бери нету уточка сложно юля споки пожар иду -- я учи нееет руб урааа лел спите чувствую утра компот состояние да сасаи хз красиво мне пошло подозреваю уебок да лол безразлично видишь вообщето соглашусь красавчик остановись трудно глупости сгинь или лошадь тупая обосрался срочно нет п смешно щегол запросто константин ем пишите вау пздц омг приезжаи милаха мне слушаю лооол кря эх безграмотность ахахах нельзя молодцы тупик танцуи часов алгебру ага кушаю лук мои годно ахахахахах работает волк ага кем-то взаимопонимание нет даваи х что поподробнее хорошо собака играть нет именно тест го гусь оооо что спасибо блестящая сос сложно спасибо до аргумент хахахаха ты надо мне нееее побью наконец-то блин какого соврал иногда завтра извиняюсь ты эи кек еб сяб да да борзыи эм на валидол милые капец кхм альфач да объясните понимаю идет нужно да ясненько к спасибо урод нечего храм поясните кыш пока е оу надоедает хер всем гордись удачи ооо есть олух угомонись норм шахматы лох оригинально желаю реклама настолько хз ау полагаю спасибо нормас питарас мне лобстер горе русские дааа игого наеб за руб лет - ээээ евреи абсолютно мдэ наверно ты млн прощаю можно намана апреля потом ну скоро правильно ? делаи посмотри заранее понятно впечатляет соврал видимо следствие всмысле месяцев сомневаюсь себе аааааа человек кхм о ничо ара лс прощаи нормальныи чеее другои печаль питух умничка всм хм группа привет так тп никто все уделал восемь оближи ээээээ спасибо валерии орех поехали понятно жалко спс ну ничто два пора шнурок ртом и грамм фотографии кирпич да аааа эм неправда негде ананас дичь услуги нет хм самсунг бедолага чувак хочется хрень эх анимация неожиданно кинь не сложна завтра вау дока всегда так-то графон рэпер согласен спс гены нет извини бред ? отстои приходи пошути поясни фууу другои яя ничему нет мерседес обои феис приезжаи большая мля счастья троль спорим скучно дурак хаюшки срочно где-то даи щас эм ъеъ привет думаю отдохни чуш пишите клево пытаешься уже осел да классно почему пфффф ок рэп сломалась шоколада зае пятнадцать тян да хм приветик повезло мои \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-ea096c98a35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<blank>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     out = greedy_decode(model, src, src_mask, \n\u001b[0;32m---> 13\u001b[0;31m                         max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Translation:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-559a5078ed62>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m      6\u001b[0m                            \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            Variable(subsequent_mask(ys.size(1))\n\u001b[0;32m----> 8\u001b[0;31m                                     .type_as(src.data)))\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-411793413c88>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, memory, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-84bcd6d9ee26>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-84bcd6d9ee26>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"Follow Figure 1 (right) for connections.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-84bcd6d9ee26>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sublayer)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msublayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"Apply residual connection to any sublayer with the same size.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-84bcd6d9ee26>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"Follow Figure 1 (right) for connections.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8daef98eab5e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# 2) Apply attention on all the projected vectors in batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         x, self.attn = attention(query, key, value, mask=mask, \n\u001b[0;32m---> 27\u001b[0;31m                                  dropout=self.dropout)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 3) \"Concat\" using a view and apply a final linear.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1934069b7914>\u001b[0m in \u001b[0;36mattention\u001b[0;34m(query, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0md_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m              \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iter):\n",
    "    src = batch.src.transpose(0, 1)[:1]\n",
    "    \n",
    "    print('Query:', end=\"\\t\")\n",
    "    for i in range(1, batch.src.size(0)):\n",
    "        sym = SRC.vocab.itos[batch.src.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\" \")\n",
    "    print()\n",
    "            \n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    out = greedy_decode(model, src, src_mask, \n",
    "                        max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "    \n",
    "    print(\"Translation:\", end=\"\\t\")\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\" \")\n",
    "    print()\n",
    "    print(\"Target:\", end=\"\\t\")\n",
    "    for i in range(1, batch.trg.size(0)):\n",
    "        sym = TGT.vocab.itos[batch.trg.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(model, models):\n",
    "    \"Average models into model\"\n",
    "    for ps in zip(*[m.params() for m in [model] + models]):\n",
    "        p[0].copy_(torch.sum(*ps[1:]) / len(ps[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type EncoderDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type EncoderLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type MultiHeadedAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type PositionwiseFeedForward. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type SublayerConnection. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type DecoderLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Embeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type PositionalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/rustammm/.local/lib/python3.5/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'chitchat.pt')\n",
    "torch.save(model_par, 'chitchat2.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Field' object has no attribute 'stoi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-da430618393b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"▁The ▁log ▁file ▁can ▁be ▁sent ▁secret ly ▁with ▁email ▁or ▁FTP ▁to ▁a ▁specified ▁receiver\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<blank>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-da430618393b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"▁The ▁log ▁file ▁can ▁be ▁sent ▁secret ly ▁with ▁email ▁or ▁FTP ▁to ▁a ▁specified ▁receiver\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<blank>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Field' object has no attribute 'stoi'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "sent = \"▁The ▁log ▁file ▁can ▁be ▁sent ▁secret ly ▁with ▁email ▁or ▁FTP ▁to ▁a ▁specified ▁receiver\".split()\n",
    "src = torch.LongTensor([[SRC.stoi[w] for w in sent]])\n",
    "src = Variable(src)\n",
    "src_mask = (src != SRC.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "out = greedy_decode(model, src, src_mask, \n",
    "                    max_len=60, start_symbol=TGT.stoi[\"<s>\"])\n",
    "print(\"Translation:\", end=\"\\t\")\n",
    "trans = \"<s> \"\n",
    "for i in range(1, out.size(1)):\n",
    "    sym = TGT.itos[out[0, i]]\n",
    "    if sym == \"</s>\": break\n",
    "    trans += sym + \" \"\n",
    "print(trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-5f2da4c9a7e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtgt_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     seaborn.heatmap(data, \n\u001b[1;32m      4\u001b[0m                     \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     cbar=False, ax=ax)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trans' is not defined"
     ]
    }
   ],
   "source": [
    "tgt_sent = trans.split()\n",
    "def draw(data, x, y, ax):\n",
    "    seaborn.heatmap(data, \n",
    "                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n",
    "                    cbar=False, ax=ax)\n",
    "    \n",
    "for layer in range(1, 6, 2):\n",
    "    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "    print(\"Encoder Layer\", layer+1)\n",
    "    for h in range(4):\n",
    "        draw(model.encoder.layers[layer].self_attn.attn[0, h].data, \n",
    "            sent, sent if h ==0 else [], ax=axs[h])\n",
    "    plt.show()\n",
    "    \n",
    "for layer in range(1, 6, 2):\n",
    "    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "    print(\"Decoder Self Layer\", layer+1)\n",
    "    for h in range(4):\n",
    "        draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)], \n",
    "            tgt_sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "    plt.show()\n",
    "    print(\"Decoder Src Layer\", layer+1)\n",
    "    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "    for h in range(4):\n",
    "        draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(sent)], \n",
    "            sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 748M\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools 122K Apr 22 03:40 Transformer.ipynb\r\n",
      "-rw------- 1 rustammm dpt_yandex_search_devtech_tools  22K Apr 21 22:11 baseline2.ipynb\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools 247M Apr 22 03:33 chitchat.pt\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools 247M Apr 22 03:33 chitchat2.pt\r\n",
      "-rw-r--r-- 1 rustammm dpt_yandex_search_devtech_tools  33M Apr 21 08:08 filtered_dataset_sm.json\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools  16M Apr 21 08:12 seq2seq.pk\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools  18M Apr 21 12:40 seq2seq2.pk\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools  36M Apr 21 17:52 seq2seq3.pk\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools  78M Apr 21 18:23 seq2seq4.pk\r\n",
      "-rw-rw-r-- 1 rustammm dpt_yandex_search_devtech_tools  78M Apr 21 18:24 seq2seq5.pk\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
