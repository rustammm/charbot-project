{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install git+https://github.com/aatimofeev/spacy_russian_tokenizer.git\n",
    "from spacy.lang.ru import Russian\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 0\n",
    "\n",
    "wv_from_bin = gensim.models.Word2Vec.load(\"ru.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITIAL_WORDS = ['лучшее', 'самое', 'важный']\n",
    "CRITIAL_WORDS_vw = [wv_from_bin[x] for x in CRITIAL_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wiki_doc_by_tokens{}.txt'.format(CHUNK)) as f:\n",
    "    docs_by_tokens = json.load(f)\n",
    "    \n",
    "with open('wiki_texts{}.txt'.format(CHUNK)) as f:\n",
    "    ps = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "count_total = sum([len(docs_by_tokens[t]) for t in docs_by_tokens.keys()])\n",
    "print(count_total)\n",
    "\n",
    "avgdl = sum([len(p) for p in ps]) / len(ps)\n",
    "print('avgdl', avgdl)\n",
    "\n",
    "nlp = Russian()\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_doc_ok(query, doc, rarest_token):\n",
    "    dc_tkns = nlp(doc)\n",
    "    if rarest_token not in [token.text for token in dc_tkns]:\n",
    "        print('No rearest')\n",
    "        return False\n",
    "    if len(doc) > len(query) * 10 or len(doc) < 7:\n",
    "        print('Size diff too big')\n",
    "        return False\n",
    "    return True\n",
    "    #wvs = []\n",
    "    #for x in dc_tkns:\n",
    "    #    try:\n",
    "    #        wvs += [wv_from_bin[x]]\n",
    "    #    except:\n",
    "    #        pass\n",
    "   # \n",
    "    # crit words\n",
    "    #if not any([np.sum((c - )**2) for c in CRITIAL_WORDS_vw])\n",
    "        \n",
    "    \n",
    "def get_score(doc, cnt_in_doc, q_docs):\n",
    "    idf = math.log((len(ps) - q_docs + 0.5) / (q_docs + 0.5))\n",
    "    return idf * cnt_in_doc * (3.5) / (cnt_in_doc + 2*(0.25 + .75 * len(ps)/avgdl)) # bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_doc(query = 'ступени в ракете'):\n",
    "    tokens =[token.text for token in nlp(query)]\n",
    "    rarest_tokens = sorted(tokens, key=lambda k: len(docs_by_tokens.get(k, [])))\n",
    "    rarest_token = None\n",
    "    for t in rarest_tokens:\n",
    "        if t in docs_by_tokens:\n",
    "            rarest_token = t\n",
    "            break\n",
    "            \n",
    "    print(tokens, rarest_token)\n",
    "    \n",
    "    if rarest_token is None:\n",
    "        return None\n",
    "    \n",
    "    best_docs = defaultdict(int)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        print(i)\n",
    "        if i > 0:\n",
    "            bigram = ' '.join([tokens[i - 1], tokens[i]])\n",
    "            docs = docs_by_tokens.get(bigram, [])\n",
    "            for d, cnt in docs_by_tokens.get(bigram, {}).items():\n",
    "                d = int(d)\n",
    "                best_docs[d] += get_score(ps[d], cnt, len(docs)) * is_doc_ok(query, ps[d], rarest_token)                \n",
    "        docs = docs_by_tokens.get(tokens[i], {}) \n",
    "        #print(docs)\n",
    "        print(i)\n",
    "        print(len(docs))\n",
    "        for d, cnt in docs.items():\n",
    "            d = int(d)\n",
    "            best_docs[d] += get_score(ps[d], cnt, len(docs)) #* is_doc_ok(query, ps[d], rarest_token)\n",
    "    \n",
    "    best_docs2 = {}\n",
    "            \n",
    "    for d in docs_by_tokens.get(rarest_token, {}):\n",
    "        d = int(d)\n",
    "        best_docs2[d] = best_docs[d]\n",
    "            \n",
    "            \n",
    "    if len(best_docs2) == 0:\n",
    "        return None\n",
    "    best_doc = sorted(best_docs2.items(), key=lambda k: k[1])[-1]\n",
    "    \n",
    "    return best_doc, is_doc_ok(query, ps[best_doc[0]], rarest_token)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['какой', 'радиус', 'земли', '?'] радиус\n",
      "0\n",
      "0\n",
      "315\n",
      "1\n",
      "1\n",
      "35\n",
      "2\n",
      "2\n",
      "1038\n",
      "3\n",
      "3\n",
      "513\n"
     ]
    }
   ],
   "source": [
    "best_doc, is_ok = get_best_doc('какой радиус земли ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75017, 0.00838127535788842), True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_doc, is_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Он установил угол наклона эклиптики к экватору, рассчитал радиус Земли, описал изменение окраски Луны при лунных затмениях и солнечную корону при солнечных затмениях'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[best_doc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
